{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tamil-georgia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-electric",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "going-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "# DE\n",
    "old_train_de = pd.read_csv(\"./datasets/train_german_data.txt\", sep=\"\\t\", header=None, names=[\"e1\", \"e2\", \"Relation\"])\n",
    "new_train_de = pd.read_csv(\"./datasets/train_german_data_new.txt\", \n",
    "                           usecols=[0,1,2], sep=\"\\t\", names=[\"e1\", \"e2\", \"Relation\"])\n",
    "\n",
    "# EN\n",
    "old_train_en = pd.read_csv(\"./datasets/train_english_data.txt\", sep=\"\\t\", header=None, names=[\"e1\", \"e2\", \"Relation\"])\n",
    "new_train_en = pd.read_csv(\"./datasets/train_english_data_new.txt\", \n",
    "                         usecols=[0,1,2], sep=\"\\t\", header=None, names=[\"e1\", \"e2\", \"Relation\"])\n",
    "\n",
    "# ZH\n",
    "old_train_zh = pd.read_csv(\"./datasets/train_chinese_data.txt\", sep=\"\\t\", header=None, names=[\"e1\", \"e2\", \"Relation\"])\n",
    "\n",
    "# Validation\n",
    "\n",
    "#DE\n",
    "old_val_de = pd.read_csv(\"./datasets/validgold_german_data.txt\", sep=\"\\t\", header=None, names=[\"e1\", \"e2\", \"Relation\"])\n",
    "new_val_de = pd.read_csv(\"./datasets/validgold_german_data_new.txt\", \n",
    "                         usecols=[0,1,2], sep=\"\\t\", header=None, names=[\"e1\", \"e2\", \"Relation\"])\n",
    "\n",
    "#EN\n",
    "old_val_en = pd.read_csv(\"./datasets/validgold_english_data.txt\", sep=\"\\t\", header=None, names=[\"e1\", \"e2\", \"Relation\"])\n",
    "new_val_en = pd.read_csv(\"./datasets/validgold_english_data_new.txt\", \n",
    "                         usecols=[0,1,2], sep=\"\\t\", header=None, names=[\"e1\", \"e2\", \"Relation\"])\n",
    "\n",
    "#ZH\n",
    "old_val_zh = pd.read_csv(\"./datasets/validgold_chinese_data.txt\", sep=\"\\t\", header=None, names=[\"e1\", \"e2\", \"Relation\"])\n",
    "\n",
    "# Test\n",
    "\n",
    "# DE\n",
    "old_test_de = pd.read_csv(\"./datasets/gold_german_data.txt\", sep=\"\\t\", header=None, names=[\"e1\", \"e2\", \"Relation\"])\n",
    "new_test_de = pd.read_csv(\"./datasets/gold_german_data_new.txt\", \n",
    "                           usecols=[0,1,2], sep=\"\\t\", names=[\"e1\", \"e2\", \"Relation\"])\n",
    "# DE\n",
    "old_test_en = pd.read_csv(\"./datasets/gold_english_data.txt\", sep=\"\\t\", header=None, names=[\"e1\", \"e2\", \"Relation\"])\n",
    "new_test_en = pd.read_csv(\"./datasets/gold_english_data_new.txt\", \n",
    "                           usecols=[0,1,2], sep=\"\\t\", names=[\"e1\", \"e2\", \"Relation\"])\n",
    "# ZH\n",
    "old_test_zh = pd.read_csv(\"./datasets/gold_chinese_data.txt\", sep=\"\\t\", header=None, names=[\"e1\", \"e2\", \"Relation\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "particular-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(old_train_de, old_train_en, old_train_zh), (old_val_de, old_val_en, old_val_zh), (old_test_de, old_test_en, old_test_zh)]\n",
    "usage = [\"Train\", \"Val\", \"Test\"]\n",
    "lang = [(\"DE\", \"EN\", \"ZH\"), (\"DE\", \"EN\", \"ZH\"), (\"DE\", \"EN\", \"ZH\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stopped-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes more sense, but stupid to put into pandas\n",
    "stat_dict = {}\n",
    "for dat, us, lan in zip(data, usage, lang):\n",
    "    for d, l in zip(dat, lan):\n",
    "        if l in stat_dict.keys():\n",
    "            stat_dict[l][us] = {}\n",
    "        else:\n",
    "            stat_dict[l] = {}\n",
    "            stat_dict[l][us] = {}\n",
    "        for i in [\"HYP\", \"SYN\", \"ANT\", \"RANDOM\" ]:\n",
    "            stat_dict[l][us][i] = d[\"Relation\"].value_counts()[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "herbal-debut",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Nicer for table\n",
    "#stat_dict = {}\n",
    "#for dat, us, lan in zip(data, usage, lang):\n",
    "#    for d, l in zip(dat, lan):\n",
    "#        for i in [\"HYP\", \"SYN\", \"ANT\", \"RANDOM\" ]:\n",
    "#            if l in stat_dict.keys():\n",
    "#                if i in stat_dict[l].keys():\n",
    "#                    stat_dict[l][i][us] = d[\"Relation\"].value_counts()[i]\n",
    "#                else:\n",
    "#                    stat_dict[l][i] = {}\n",
    "#                    stat_dict[l][i][us] = d[\"Relation\"].value_counts()[i]\n",
    "#            else:\n",
    "#                stat_dict[l] = {}\n",
    "#                stat_dict[l][i] = {}\n",
    "#                stat_dict[l][i][us] = d[\"Relation\"].value_counts()[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "harmful-worker",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'DE': {'Train': {'HYP': 841, 'SYN': 782, 'ANT': 829, 'RANDOM': 2430}, 'Val': {'HYP': 294, 'SYN': 272, 'ANT': 275, 'RANDOM': 786}, 'Test': {'HYP': 286, 'SYN': 265, 'ANT': 281, 'RANDOM': 796}}, 'EN': {'Train': {'HYP': 898, 'SYN': 842, 'ANT': 916, 'RANDOM': 2554}, 'Val': {'HYP': 292, 'SYN': 259, 'ANT': 308, 'RANDOM': 877}, 'Test': {'HYP': 279, 'SYN': 266, 'ANT': 306, 'RANDOM': 887}}, 'ZH': {'Train': {'HYP': 421, 'SYN': 402, 'ANT': 361, 'RANDOM': 1330}, 'Val': {'HYP': 145, 'SYN': 129, 'ANT': 136, 'RANDOM': 428}, 'Test': {'HYP': 129, 'SYN': 122, 'ANT': 142, 'RANDOM': 445}}}\n"
     ]
    }
   ],
   "source": [
    "print(stat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fitted-projection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('DE', 'Train'): {'HYP': 841, 'SYN': 782, 'ANT': 829, 'RANDOM': 2430}, ('DE', 'Val'): {'HYP': 294, 'SYN': 272, 'ANT': 275, 'RANDOM': 786}, ('DE', 'Test'): {'HYP': 286, 'SYN': 265, 'ANT': 281, 'RANDOM': 796}, ('EN', 'Train'): {'HYP': 898, 'SYN': 842, 'ANT': 916, 'RANDOM': 2554}, ('EN', 'Val'): {'HYP': 292, 'SYN': 259, 'ANT': 308, 'RANDOM': 877}, ('EN', 'Test'): {'HYP': 279, 'SYN': 266, 'ANT': 306, 'RANDOM': 887}, ('ZH', 'Train'): {'HYP': 421, 'SYN': 402, 'ANT': 361, 'RANDOM': 1330}, ('ZH', 'Val'): {'HYP': 145, 'SYN': 129, 'ANT': 136, 'RANDOM': 428}, ('ZH', 'Test'): {'HYP': 129, 'SYN': 122, 'ANT': 142, 'RANDOM': 445}}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">DE</th>\n",
       "      <th colspan=\"3\" halign=\"left\">EN</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ZH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Val</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train</th>\n",
       "      <th>Val</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train</th>\n",
       "      <th>Val</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HYP</th>\n",
       "      <td>841</td>\n",
       "      <td>294</td>\n",
       "      <td>286</td>\n",
       "      <td>898</td>\n",
       "      <td>292</td>\n",
       "      <td>279</td>\n",
       "      <td>421</td>\n",
       "      <td>145</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SYN</th>\n",
       "      <td>782</td>\n",
       "      <td>272</td>\n",
       "      <td>265</td>\n",
       "      <td>842</td>\n",
       "      <td>259</td>\n",
       "      <td>266</td>\n",
       "      <td>402</td>\n",
       "      <td>129</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANT</th>\n",
       "      <td>829</td>\n",
       "      <td>275</td>\n",
       "      <td>281</td>\n",
       "      <td>916</td>\n",
       "      <td>308</td>\n",
       "      <td>306</td>\n",
       "      <td>361</td>\n",
       "      <td>136</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RANDOM</th>\n",
       "      <td>2430</td>\n",
       "      <td>786</td>\n",
       "      <td>796</td>\n",
       "      <td>2554</td>\n",
       "      <td>877</td>\n",
       "      <td>887</td>\n",
       "      <td>1330</td>\n",
       "      <td>428</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DE              EN              ZH          \n",
       "       Train  Val Test Train  Val Test Train  Val Test\n",
       "HYP      841  294  286   898  292  279   421  145  129\n",
       "SYN      782  272  265   842  259  266   402  129  122\n",
       "ANT      829  275  281   916  308  306   361  136  142\n",
       "RANDOM  2430  786  796  2554  877  887  1330  428  445"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_df = pd.DataFrame(stat_dict)\n",
    "reformed_dict = {}\n",
    "for outerKey, innerDict in stat_dict.items():\n",
    "    for innerKey, values in innerDict.items():\n",
    "        reformed_dict[(outerKey,\n",
    "                       innerKey)] = values\n",
    "print(reformed_dict)\n",
    "stat_df = pd.DataFrame(reformed_dict)\n",
    "stat_df\n",
    "#stat_df.to_latex(\"./stats/data_stats.tex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-north",
   "metadata": {},
   "source": [
    "# Training Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "national-halifax",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare DataFrames\n",
    "comp_train_de = old_train_de.compare(new_train_de, keep_equal=True)\n",
    "comp_train_en = old_train_en.compare(new_train_en, keep_equal=True)\n",
    "comp_val_de = old_val_de.compare(new_val_de, keep_equal=True)\n",
    "comp_val_en = old_val_en.compare(new_val_en, keep_equal=True)\n",
    "comp_test_de = old_test_de.compare(new_test_de, keep_equal=True)\n",
    "comp_test_en = old_test_en.compare(new_test_en, keep_equal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "computational-option",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train\n",
      "Val\n",
      "Test\n",
      "Train\n",
      "Val\n",
      "Test\n",
      "Train\n",
      "Val\n",
      "Test\n",
      "{('DE', 'Train'): {'HYP': 594, 'SYN': 402, 'ANT': 399, 'RANDOM': 1039}, ('DE', 'Val'): {'HYP': 213, 'SYN': 152, 'ANT': 146, 'RANDOM': 308}, ('DE', 'Test'): {'HYP': 166, 'SYN': 134, 'ANT': 134, 'RANDOM': 303}, ('EN', 'Train'): {'HYP': 320, 'SYN': 293, 'ANT': 311, 'RANDOM': 213}, ('EN', 'Val'): {'HYP': 149, 'SYN': 103, 'ANT': 117, 'RANDOM': 70}, ('EN', 'Test'): {'HYP': 121, 'SYN': 115, 'ANT': 94, 'RANDOM': 61}, ('ZH', 'Train'): {'HYP': 'TBD', 'SYN': 'TBD', 'ANT': 'TBD', 'RANDOM': 'TBD'}, ('ZH', 'Val'): {'HYP': 'TBD', 'SYN': 'TBD', 'ANT': 'TBD', 'RANDOM': 'TBD'}, ('ZH', 'Test'): {'HYP': 'TBD', 'SYN': 'TBD', 'ANT': 'TBD', 'RANDOM': 'TBD'}}\n"
     ]
    }
   ],
   "source": [
    "data = [(comp_train_de, comp_train_en, \"placeholder\"),\n",
    "        (comp_val_de, comp_val_en, \"placeholder\"), \n",
    "        (comp_test_de, comp_test_en, \"placeholder\")]\n",
    "usage = [\"Train\", \"Val\", \"Test\"]\n",
    "langs = [\"DE\", \"EN\", \"ZH\"]\n",
    "\n",
    "changed_stats = {}\n",
    "for idx, lang in enumerate(langs):\n",
    "    for d, us in zip(data,usage):\n",
    "        print(us)\n",
    "        for rel in [\"HYP\", \"SYN\", \"ANT\", \"RANDOM\" ]:\n",
    "            ready = True\n",
    "            try:\n",
    "                d[idx][\"Relation\"][\"self\"].value_counts()[rel]\n",
    "                #print(lang, rel, rel, d[\"Relation\"][\"self\"].value_counts()[rel])\n",
    "                ready = True                \n",
    "            except:\n",
    "                #print(lang, rel, rel, \"TBD\")\n",
    "                ready = False\n",
    "            if ready:\n",
    "                if (lang, us) not in changed_stats.keys():\n",
    "                    changed_stats[(lang, us)] = {rel: d[idx][\"Relation\"][\"self\"].value_counts()[rel]}\n",
    "                else:\n",
    "                    changed_stats[(lang, us)][rel] = d[idx][\"Relation\"][\"self\"].value_counts()[rel]\n",
    "            else:\n",
    "                if (lang, us) not in changed_stats.keys():\n",
    "                    changed_stats[(lang, us)] = {rel: \"TBD\"}\n",
    "                else:\n",
    "                    changed_stats[(lang, us)][rel] = \"TBD\"\n",
    "\n",
    "\n",
    "print(changed_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "english-landing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">DE</th>\n",
       "      <th colspan=\"3\" halign=\"left\">EN</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ZH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Val</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train</th>\n",
       "      <th>Val</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train</th>\n",
       "      <th>Val</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HYP</th>\n",
       "      <td>594</td>\n",
       "      <td>213</td>\n",
       "      <td>166</td>\n",
       "      <td>320</td>\n",
       "      <td>149</td>\n",
       "      <td>121</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SYN</th>\n",
       "      <td>402</td>\n",
       "      <td>152</td>\n",
       "      <td>134</td>\n",
       "      <td>293</td>\n",
       "      <td>103</td>\n",
       "      <td>115</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANT</th>\n",
       "      <td>399</td>\n",
       "      <td>146</td>\n",
       "      <td>134</td>\n",
       "      <td>311</td>\n",
       "      <td>117</td>\n",
       "      <td>94</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RANDOM</th>\n",
       "      <td>1039</td>\n",
       "      <td>308</td>\n",
       "      <td>303</td>\n",
       "      <td>213</td>\n",
       "      <td>70</td>\n",
       "      <td>61</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DE              EN              ZH          \n",
       "       Train  Val Test Train  Val Test Train  Val Test\n",
       "HYP      594  213  166   320  149  121   TBD  TBD  TBD\n",
       "SYN      402  152  134   293  103  115   TBD  TBD  TBD\n",
       "ANT      399  146  134   311  117   94   TBD  TBD  TBD\n",
       "RANDOM  1039  308  303   213   70   61   TBD  TBD  TBD"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_df = pd.DataFrame(changed_stats)\n",
    "change_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "civic-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "change_df.to_latex(\"./stats/change_stats.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "polish-campaign",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HYP       320\n",
       "ANT       311\n",
       "SYN       293\n",
       "RANDOM    213\n",
       "Name: self, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_df = old_train_en.compare(new_train_en, keep_equal=True)\n",
    "comp_df[\"Relation\"][\"self\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "about-intro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "      <th>Change in %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [self, other, Change in %]\n",
       "Index: []"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_counts = comp_df[\"Relation\"][\"self\"].value_counts(sort=False).compare(comp_df[\"Relation\"][\"other\"].value_counts(sort=False))\n",
    "comp_counts[\"Change in %\"] = round((comp_counts.other - comp_counts.self)/comp_counts.self * 100, 2)\n",
    "comp_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "gothic-ghana",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_HYP_idx = comp_df.index[comp_df[\"Relation\"][\"self\"].str.contains(\"HYP\", na=False)]\n",
    "old_SYN_idx = comp_df.index[comp_df[\"Relation\"][\"self\"].str.contains(\"SYN\", na=False)]\n",
    "old_ANT_idx = comp_df.index[comp_df[\"Relation\"][\"self\"].str.contains(\"ANT\", na=False)]\n",
    "old_RND_idx = comp_df.index[comp_df[\"Relation\"][\"self\"].str.contains(\"RANDOM\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "independent-oasis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYP was changed to:\n",
      "\n",
      "SYN 19 times\n",
      "ANT 2 times\n",
      "RANDOM 1 times\n",
      "\n",
      "HYP was kept:\n",
      "\n",
      "298 times\n"
     ]
    }
   ],
   "source": [
    "#hyp_to = comp_df.loc[old_HYP_idx][\"Relation\"][\"other\"].drop(comp_df.loc[old_HYP_idx].index[comp_df.loc[old_HYP_idx].Relation.other == \"HYP\"]).value_counts()\n",
    "print(\"HYP was changed to:\\n\")\n",
    "for index, value in comp_df.loc[old_HYP_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index != \"HYP\":\n",
    "        print(index, value, \"times\")\n",
    "print(\"\\nHYP was kept:\\n\")\n",
    "for index, value in comp_df.loc[old_HYP_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index == \"HYP\":\n",
    "        print(value, \"times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "daily-absorption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYN was changed to:\n",
      "\n",
      "HYP 19 times\n",
      "ANT 3 times\n",
      "RANDOM 1 times\n",
      "\n",
      "SYN was kept:\n",
      "\n",
      "270 times\n"
     ]
    }
   ],
   "source": [
    "print(\"SYN was changed to:\\n\")\n",
    "for index, value in comp_df.loc[old_SYN_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index != \"SYN\":\n",
    "        print(index, value, \"times\")\n",
    "print(\"\\nSYN was kept:\\n\")\n",
    "for index, value in comp_df.loc[old_SYN_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index == \"SYN\":\n",
    "        print(value, \"times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "compatible-denmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANT was changed to:\n",
      "\n",
      "SYN 3 times\n",
      "HYP 2 times\n",
      "\n",
      "ANT was kept:\n",
      "\n",
      "306 times\n"
     ]
    }
   ],
   "source": [
    "print(\"ANT was changed to:\\n\")\n",
    "for index, value in comp_df.loc[old_ANT_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index != \"ANT\":\n",
    "        print(index, value, \"times\")\n",
    "print(\"\\nANT was kept:\\n\")\n",
    "for index, value in comp_df.loc[old_ANT_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index == \"ANT\":\n",
    "        print(value, \"times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "pointed-hunger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM was changed to:\n",
      "\n",
      "HYP 1 times\n",
      "SYN 1 times\n",
      "\n",
      "RANDOM was kept:\n",
      "\n",
      "211 times\n"
     ]
    }
   ],
   "source": [
    "print(\"RANDOM was changed to:\\n\")\n",
    "for index, value in comp_df.loc[old_RND_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index != \"RANDOM\":\n",
    "        print(index, value, \"times\")\n",
    "print(\"\\nRANDOM was kept:\\n\")\n",
    "for index, value in comp_df.loc[old_RND_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index == \"RANDOM\":\n",
    "        print(value, \"times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-concentration",
   "metadata": {},
   "source": [
    "# Validation Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "incorporate-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df = old_val_en.compare(new_val_en, keep_equal=True)\n",
    "#comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "false-cover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "      <th>Change in %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [self, other, Change in %]\n",
       "Index: []"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_counts = comp_df[\"Relation\"][\"self\"].value_counts(sort=False).compare(comp_df[\"Relation\"][\"other\"].value_counts(sort=False))\n",
    "comp_counts[\"Change in %\"] = round((comp_counts.other - comp_counts.self)/comp_counts.self * 100, 2)\n",
    "comp_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "listed-express",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_HYP_idx = comp_df.index[comp_df[\"Relation\"][\"self\"].str.contains(\"HYP\", na=False)]\n",
    "old_SYN_idx = comp_df.index[comp_df[\"Relation\"][\"self\"].str.contains(\"SYN\", na=False)]\n",
    "old_ANT_idx = comp_df.index[comp_df[\"Relation\"][\"self\"].str.contains(\"ANT\", na=False)]\n",
    "old_RND_idx = comp_df.index[comp_df[\"Relation\"][\"self\"].str.contains(\"RANDOM\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "southwest-enough",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYP was changed to:\n",
      "\n",
      "SYN 20 times\n",
      "RANDOM 1 times\n",
      "\n",
      "HYP was kept:\n",
      "\n",
      "128 times\n"
     ]
    }
   ],
   "source": [
    "#hyp_to = comp_df.loc[old_HYP_idx][\"Relation\"][\"other\"].drop(comp_df.loc[old_HYP_idx].index[comp_df.loc[old_HYP_idx].Relation.other == \"HYP\"]).value_counts()\n",
    "print(\"HYP was changed to:\\n\")\n",
    "for index, value in comp_df.loc[old_HYP_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index != \"HYP\":\n",
    "        print(index, value, \"times\")\n",
    "print(\"\\nHYP was kept:\\n\")\n",
    "for index, value in comp_df.loc[old_HYP_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index == \"HYP\":\n",
    "        print(value, \"times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "iraqi-method",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYN was changed to:\n",
      "\n",
      "HYP 20 times\n",
      "\n",
      "SYN was kept:\n",
      "\n",
      "83 times\n"
     ]
    }
   ],
   "source": [
    "print(\"SYN was changed to:\\n\")\n",
    "for index, value in comp_df.loc[old_SYN_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index != \"SYN\":\n",
    "        print(index, value, \"times\")\n",
    "print(\"\\nSYN was kept:\\n\")\n",
    "for index, value in comp_df.loc[old_SYN_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index == \"SYN\":\n",
    "        print(value, \"times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "armed-honey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANT was changed to:\n",
      "\n",
      "RANDOM 3 times\n",
      "\n",
      "ANT was kept:\n",
      "\n",
      "114 times\n"
     ]
    }
   ],
   "source": [
    "print(\"ANT was changed to:\\n\")\n",
    "for index, value in comp_df.loc[old_ANT_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index != \"ANT\":\n",
    "        print(index, value, \"times\")\n",
    "print(\"\\nANT was kept:\\n\")\n",
    "for index, value in comp_df.loc[old_ANT_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index == \"ANT\":\n",
    "        print(value, \"times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "naval-buffer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM was changed to:\n",
      "\n",
      "ANT 3 times\n",
      "HYP 1 times\n",
      "\n",
      "RANDOM was kept:\n",
      "\n",
      "66 times\n"
     ]
    }
   ],
   "source": [
    "print(\"RANDOM was changed to:\\n\")\n",
    "for index, value in comp_df.loc[old_RND_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index != \"RANDOM\":\n",
    "        print(index, value, \"times\")\n",
    "print(\"\\nRANDOM was kept:\\n\")\n",
    "for index, value in comp_df.loc[old_RND_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index == \"RANDOM\":\n",
    "        print(value, \"times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-farmer",
   "metadata": {},
   "source": [
    "# Test Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "parental-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df = old_test_de.compare(new_test_de, keep_equal=True)\n",
    "#comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "checked-reason",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "      <th>Change in %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [self, other, Change in %]\n",
       "Index: []"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_counts = comp_df[\"Relation\"][\"self\"].value_counts(sort=False).compare(comp_df[\"Relation\"][\"other\"].value_counts(sort=False))\n",
    "comp_counts[\"Change in %\"] = round((comp_counts.other - comp_counts.self)/comp_counts.self * 100, 2)\n",
    "comp_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "superb-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_HYP_idx = comp_df.index[comp_df[\"Relation\"][\"self\"].str.contains(\"HYP\", na=False)]\n",
    "old_SYN_idx = comp_df.index[comp_df[\"Relation\"][\"self\"].str.contains(\"SYN\", na=False)]\n",
    "old_ANT_idx = comp_df.index[comp_df[\"Relation\"][\"self\"].str.contains(\"ANT\", na=False)]\n",
    "old_RND_idx = comp_df.index[comp_df[\"Relation\"][\"self\"].str.contains(\"RANDOM\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "developing-afternoon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYP was changed to:\n",
      "\n",
      "SYN 10 times\n",
      "ANT 6 times\n",
      "\n",
      "HYP was kept:\n",
      "\n",
      "150 times\n"
     ]
    }
   ],
   "source": [
    "#hyp_to = comp_df.loc[old_HYP_idx][\"Relation\"][\"other\"].drop(comp_df.loc[old_HYP_idx].index[comp_df.loc[old_HYP_idx].Relation.other == \"HYP\"]).value_counts()\n",
    "print(\"HYP was changed to:\\n\")\n",
    "for index, value in comp_df.loc[old_HYP_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index != \"HYP\":\n",
    "        print(index, value, \"times\")\n",
    "print(\"\\nHYP was kept:\\n\")\n",
    "for index, value in comp_df.loc[old_HYP_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index == \"HYP\":\n",
    "        print(value, \"times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "short-china",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYN was changed to:\n",
      "\n",
      "HYP 10 times\n",
      "ANT 1 times\n",
      "RANDOM 1 times\n",
      "\n",
      "SYN was kept:\n",
      "\n",
      "122 times\n"
     ]
    }
   ],
   "source": [
    "print(\"SYN was changed to:\\n\")\n",
    "for index, value in comp_df.loc[old_SYN_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index != \"SYN\":\n",
    "        print(index, value, \"times\")\n",
    "print(\"\\nSYN was kept:\\n\")\n",
    "for index, value in comp_df.loc[old_SYN_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index == \"SYN\":\n",
    "        print(value, \"times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "mounted-teddy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANT was changed to:\n",
      "\n",
      "HYP 5 times\n",
      "SYN 2 times\n",
      "RANDOM 1 times\n",
      "\n",
      "ANT was kept:\n",
      "\n",
      "126 times\n"
     ]
    }
   ],
   "source": [
    "print(\"ANT was changed to:\\n\")\n",
    "for index, value in comp_df.loc[old_ANT_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index != \"ANT\":\n",
    "        print(index, value, \"times\")\n",
    "print(\"\\nANT was kept:\\n\")\n",
    "for index, value in comp_df.loc[old_ANT_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index == \"ANT\":\n",
    "        print(value, \"times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "final-gravity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM was changed to:\n",
      "\n",
      "ANT 1 times\n",
      "HYP 1 times\n",
      "\n",
      "RANDOM was kept:\n",
      "\n",
      "301 times\n"
     ]
    }
   ],
   "source": [
    "print(\"RANDOM was changed to:\\n\")\n",
    "for index, value in comp_df.loc[old_RND_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index != \"RANDOM\":\n",
    "        print(index, value, \"times\")\n",
    "print(\"\\nRANDOM was kept:\\n\")\n",
    "for index, value in comp_df.loc[old_RND_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index == \"RANDOM\":\n",
    "        print(value, \"times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-arthritis",
   "metadata": {},
   "source": [
    "# Clean Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "needed-agenda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "ds_val = new_val_en.loc[new_val_en.duplicated(subset=[\"e1\",\"e2\"])]\n",
    "print(\"Duplicates:\", ds_val[\"Relation\"].count())\n",
    "for i, r in ds_val.iterrows():\n",
    "    print (i + 1, r[\"e1\"], r[\"e2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "extraordinary-costume",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "ds_train = new_train_en.loc[new_train_en.duplicated(subset=[\"e1\",\"e2\"])]\n",
    "print(\"Duplicates:\", ds_train[\"Relation\"].count())\n",
    "for i, r in ds_train.iterrows():\n",
    "    print (i + 1, r[\"e1\"], r[\"e2\"], r[\"Relation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dressed-correspondence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "ds_test = new_test_en.loc[new_test_en.duplicated(subset=[\"e1\",\"e2\"])]\n",
    "print(\"Duplicates:\", ds_test[\"Relation\"].count())\n",
    "for i, r in ds_test.iterrows():\n",
    "    print (i + 1, r[\"e1\"], r[\"e2\"], r[\"Relation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-berkeley",
   "metadata": {},
   "source": [
    "## Clean reverse duplicates (Rename Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "casual-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_train_en_rev = old_train_en.rename(columns={\"e1\":\"e2\", \"e2\":\"e1\"})\n",
    "new_train_en_rev = new_train_en.rename(columns={\"e1\":\"e2\", \"e2\":\"e1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "brutal-giant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "dub_train = pd.concat([new_train_en, new_train_en_rev])\n",
    "print(\"Duplicates:\", dub_train.loc[dub_train.duplicated(subset=[\"e1\",\"e2\"])][\"e1\"].count())\n",
    "for i, r in dub_train.loc[dub_train.duplicated(subset=[\"e1\",\"e2\"])].iterrows():\n",
    "    print(i+1, r['e1'], r['e2'],r['Relation'], \"/\", new_train_en.loc[i]['Relation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "surrounded-leadership",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "new_val_en_rev = new_val_en.rename(columns={\"e1\":\"e2\", \"e2\":\"e1\"})\n",
    "old_val_en_rev = old_val_en.rename(columns={\"e1\":\"e2\", \"e2\":\"e1\"})\n",
    "dub_val = pd.concat([new_val_en, new_val_en_rev])\n",
    "print(\"Duplicates:\", dub_val.loc[dub_val.duplicated(subset=[\"e1\",\"e2\"])][\"e1\"].count())\n",
    "for i, r in dub_val.loc[dub_val.duplicated(subset=[\"e1\",\"e2\"])].iterrows():\n",
    "    print(i+1, r['e1'], r['e2'],r['Relation'], \"/\", new_val_en.loc[i]['Relation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "defined-symphony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "new_test_en_rev = new_test_en.rename(columns={\"e1\":\"e2\", \"e2\":\"e1\"})\n",
    "old_test_en_rev = old_test_en.rename(columns={\"e1\":\"e2\", \"e2\":\"e1\"})\n",
    "dub_val = pd.concat([new_test_en, new_test_en_rev])\n",
    "print(\"Duplicates:\", dub_val.loc[dub_val.duplicated(subset=[\"e1\",\"e2\"])][\"e1\"].count())\n",
    "for i, r in dub_val.loc[dub_val.duplicated(subset=[\"e1\",\"e2\"])].iterrows():\n",
    "    print(i+1, r['e1'], r['e2'],r['Relation'], \"/\", new_test_en.loc[i]['Relation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "specified-salad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "dub_all = pd.concat([new_test_en, new_train_en, new_train_en_rev,new_val_en], ignore_index=False)\n",
    "print(\"Duplicates:\", dub_all.loc[dub_all.duplicated(subset=[\"e1\",\"e2\"])][\"e1\"].count())\n",
    "for i,r in dub_all.loc[dub_all.duplicated(subset=[\"e1\",\"e2\"], keep=False)].iterrows():\n",
    "    print(i +1, r[\"e1\"], r[\"e2\"], r[\"Relation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-bones",
   "metadata": {},
   "source": [
    "# Check Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "anticipated-stamp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 106\n",
      "86 渾 清 ANT\n",
      "98 武 文 ANT\n",
      "111 婆 公公 ANT\n",
      "128 僅僅 只不過 SYN\n",
      "163 香 臭 ANT\n",
      "253 爺 奶 ANT\n",
      "336 以至於 以至 SYN\n",
      "359 臭 香 ANT\n",
      "463 出去 進來 ANT\n",
      "475 兒子 女兒 ANT\n",
      "541 下台 下臺 SYN\n",
      "621 下臺 上臺 ANT\n",
      "627 只不過 僅僅 SYN\n",
      "688 公公 婆 ANT\n",
      "897 之內 以外 ANT\n",
      "945 裡頭 以外 ANT\n",
      "955 況且 更何況 SYN\n",
      "973 以內 之外 ANT\n",
      "1047 以至 以至於 SYN\n",
      "1101 娘 父親 ANT\n",
      "1159 甚至 甚至於 SYN\n",
      "1269 下臺 下台 SYN\n",
      "1306 孩子 小孩子 SYN\n",
      "1314 文 武 ANT\n",
      "1410 之外 以內 ANT\n",
      "1417 以外 之內 ANT\n",
      "1518 更何況 況且 SYN\n",
      "1526 出去 進 ANT\n",
      "1548 中國人 華人 SYN\n",
      "1568 以內 以外 ANT\n",
      "1620 祇不過 僅有 SYN\n",
      "1631 上面 下面 ANT\n",
      "1653 清 渾 ANT\n",
      "1733 順道 特 ANT\n",
      "1795 下面 上面 ANT\n",
      "1804 僅有 祇不過 SYN\n",
      "1853 吐出 吐出來 SYN\n",
      "1891 上臺 下臺 ANT\n",
      "1909 以外 以內 ANT\n",
      "1911 父親 娘 ANT\n",
      "1920 對不起 抱歉 SYN\n",
      "1933 以外 裡頭 ANT\n",
      "1989 甚至於 甚至 SYN\n",
      "2027 吐出來 吐出 SYN\n",
      "2046 奶 爺 ANT\n",
      "2061 來不及 來得及 ANT\n",
      "2074 進來 出去 ANT\n",
      "2121 女兒 兒子 ANT\n",
      "2148 那兒 這裏 RANDOM\n",
      "2152 進 出去 ANT\n",
      "2209 來得及 來不及 ANT\n",
      "2240 小孩子 孩子 SYN\n",
      "2270 這裏 那兒 ANT\n",
      "2307 抱歉 對不起 SYN\n",
      "2490 特 順道 ANT\n",
      "2498 華人 中國人 SYN\n",
      "35 以內 外面 ANT\n",
      "92 不僅僅 不只 SYN\n",
      "186 右 左邊 ANT\n",
      "223 媽媽 父 ANT\n",
      "226 順道 特意 ANT\n",
      "256 特地 順道 ANT\n",
      "284 只不過 祇是 SYN\n",
      "299 一點兒 一點 SYN\n",
      "302 只不過 祇 SYN\n",
      "346 更何況 何況 SYN\n",
      "372 四川省 四川 SYN\n",
      "465 之后 之前 ANT\n",
      "512 之下 之上 ANT\n",
      "530 裡頭 外面 ANT\n",
      "579 強烈 弱 ANT\n",
      "621 良性 惡性 ANT\n",
      "688 外面 內部 ANT\n",
      "716 這樣 這樣子 SYN\n",
      "721 先生 太太 ANT\n",
      "727 利益 弊 ANT\n",
      "781 吞下去 吞 SYN\n",
      "814 父 母親 ANT\n",
      "81 要不然 要不 SYN\n",
      "110 只是 祇不過 SYN\n",
      "111 行 不行 ANT\n",
      "173 出於 來自於 SYN\n",
      "186 研究院 研究所 SYN\n",
      "190 不然 要不然 SYN\n",
      "225 洗衣 洗衣服 SYN\n",
      "233 不僅僅 不止 SYN\n",
      "242 下臺 上台 ANT\n",
      "292 臺南 台南 SYN\n",
      "370 以前 後 ANT\n",
      "389 入 出來 ANT\n",
      "412 夫 妻子 ANT\n",
      "428 哥哥 弟 ANT\n",
      "454 之內 之外 ANT\n",
      "481 圍起來 圍起 SYN\n",
      "486 弊 好處 ANT\n",
      "487 有心人士 有心人 SYN\n",
      "547 直接 間接 ANT\n",
      "554 指引 失落 RANDOM\n",
      "579 吃掉 吃下去 SYN\n",
      "600 開 關 ANT\n",
      "632 白 黑 ANT\n",
      "701 下面 之上 ANT\n",
      "746 不到 到 ANT\n",
      "757 最少 最多 ANT\n",
      "766 弟兄 姐妹 ANT\n",
      "791 以下 之上 ANT\n"
     ]
    }
   ],
   "source": [
    "old_train_zh_rev = old_train_zh.rename(columns={\"e1\":\"e2\", \"e2\":\"e1\"})\n",
    "dub_all = pd.concat([old_train_zh, old_train_zh_rev, old_val_zh, old_test_zh], ignore_index=False)\n",
    "print(\"Duplicates:\", dub_all.loc[dub_all.duplicated(subset=[\"e1\",\"e2\"])][\"e1\"].count())\n",
    "for i,r in dub_all.loc[dub_all.duplicated(subset=[\"e1\",\"e2\"])].iterrows():\n",
    "    print(i +1, r[\"e1\"], r[\"e2\"], r[\"Relation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hydraulic-failure",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-restoration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d31228",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32aeaabe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5b4301",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
