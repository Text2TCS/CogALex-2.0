{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "tamil-georgia",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "committed-electric",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "going-nirvana",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "# DE\n",
    "old_train_de = pd.read_csv(\"../CogALex 1.0/train_german_data.txt\", sep=\"\\t\", header=None, names=[\"e1\", \"e2\", \"Relation\"])\n",
    "new_train_de = pd.read_csv(\"../CogALex 2.0/train_german_data_new.txt\", \n",
    "                           usecols=[0,1,2], sep=\"\\t\", names=[\"e1\", \"e2\", \"Relation\"])\n",
    "\n",
    "# EN\n",
    "old_train_en = pd.read_csv(\"../CogALex 1.0/train_english_data.txt\", sep=\"\\t\", header=None, names=[\"e1\", \"e2\", \"Relation\"])\n",
    "new_train_en = pd.read_csv(\"../CogALex 2.0/train_english_data_new.txt\", \n",
    "                         usecols=[0,1,2], sep=\"\\t\", header=None, names=[\"e1\", \"e2\", \"Relation\"])\n",
    "\n",
    "# ZH\n",
    "old_train_zh = pd.read_csv(\"../CogALex 1.0/train_chinese_data.txt\", sep=\"\\t\", header=None, names=[\"e1\", \"e2\", \"Relation\"])\n",
    "\n",
    "# Validation\n",
    "\n",
    "#DE\n",
    "old_val_de = pd.read_csv(\"../CogALex 1.0/validgold_german_data.txt\", sep=\"\\t\", header=None, names=[\"e1\", \"e2\", \"Relation\"])\n",
    "new_val_de = pd.read_csv(\"../CogALex 2.0/validgold_german_data_new.txt\", \n",
    "                         usecols=[0,1,2], sep=\"\\t\", header=None, names=[\"e1\", \"e2\", \"Relation\"])\n",
    "\n",
    "#EN\n",
    "old_val_en = pd.read_csv(\"../CogALex 1.0/validgold_english_data.txt\", sep=\"\\t\", header=None, names=[\"e1\", \"e2\", \"Relation\"])\n",
    "new_val_en = pd.read_csv(\"../CogALex 2.0/validgold_english_data_new.txt\", \n",
    "                         usecols=[0,1,2], sep=\"\\t\", header=None, names=[\"e1\", \"e2\", \"Relation\"])\n",
    "\n",
    "#ZH\n",
    "old_val_zh = pd.read_csv(\"../CogALex 1.0/validgold_chinese_data.txt\", sep=\"\\t\", header=None, names=[\"e1\", \"e2\", \"Relation\"])\n",
    "\n",
    "# Test\n",
    "\n",
    "# DE\n",
    "old_test_de = pd.read_csv(\"../CogALex 1.0/gold_german_data.txt\", sep=\"\\t\", header=None, names=[\"e1\", \"e2\", \"Relation\"])\n",
    "new_test_de = pd.read_csv(\"../CogALex 2.0/gold_german_data_new.txt\", \n",
    "                           usecols=[0,1,2], sep=\"\\t\", names=[\"e1\", \"e2\", \"Relation\"])\n",
    "# DE\n",
    "old_test_en = pd.read_csv(\"../CogALex 1.0/gold_english_data.txt\", sep=\"\\t\", header=None, names=[\"e1\", \"e2\", \"Relation\"])\n",
    "new_test_en = pd.read_csv(\"../CogALex 2.0/gold_english_data_new.txt\", \n",
    "                           usecols=[0,1,2], sep=\"\\t\", names=[\"e1\", \"e2\", \"Relation\"])\n",
    "# ZH\n",
    "old_test_zh = pd.read_csv(\"../CogALex 1.0/gold_chinese_data.txt\", sep=\"\\t\", header=None, names=[\"e1\", \"e2\", \"Relation\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "particular-bicycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(old_train_de, old_train_en, old_train_zh), (old_val_de, old_val_en, old_val_zh), (old_test_de, old_test_en, old_test_zh)]\n",
    "usage = [\"Train\", \"Val\", \"Test\"]\n",
    "lang = [(\"DE\", \"EN\", \"ZH\"), (\"DE\", \"EN\", \"ZH\"), (\"DE\", \"EN\", \"ZH\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stopped-tourist",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Makes more sense, but stupid to put into pandas\n",
    "stat_dict = {}\n",
    "for dat, us, lan in zip(data, usage, lang):\n",
    "    for d, l in zip(dat, lan):\n",
    "        if l in stat_dict.keys():\n",
    "            stat_dict[l][us] = {}\n",
    "        else:\n",
    "            stat_dict[l] = {}\n",
    "            stat_dict[l][us] = {}\n",
    "        for i in [\"HYP\", \"SYN\", \"ANT\", \"RANDOM\" ]:\n",
    "            stat_dict[l][us][i] = d[\"Relation\"].value_counts()[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "harmful-worker",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(stat_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fitted-projection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">DE</th>\n",
       "      <th colspan=\"3\" halign=\"left\">EN</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ZH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Val</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train</th>\n",
       "      <th>Val</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train</th>\n",
       "      <th>Val</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>HYP</th>\n",
       "      <td>841</td>\n",
       "      <td>294</td>\n",
       "      <td>286</td>\n",
       "      <td>898</td>\n",
       "      <td>292</td>\n",
       "      <td>279</td>\n",
       "      <td>421</td>\n",
       "      <td>145</td>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SYN</th>\n",
       "      <td>782</td>\n",
       "      <td>272</td>\n",
       "      <td>265</td>\n",
       "      <td>842</td>\n",
       "      <td>259</td>\n",
       "      <td>266</td>\n",
       "      <td>402</td>\n",
       "      <td>129</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ANT</th>\n",
       "      <td>829</td>\n",
       "      <td>275</td>\n",
       "      <td>281</td>\n",
       "      <td>916</td>\n",
       "      <td>308</td>\n",
       "      <td>306</td>\n",
       "      <td>361</td>\n",
       "      <td>136</td>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RANDOM</th>\n",
       "      <td>2430</td>\n",
       "      <td>786</td>\n",
       "      <td>796</td>\n",
       "      <td>2554</td>\n",
       "      <td>877</td>\n",
       "      <td>887</td>\n",
       "      <td>1330</td>\n",
       "      <td>428</td>\n",
       "      <td>445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DE              EN              ZH          \n",
       "       Train  Val Test Train  Val Test Train  Val Test\n",
       "HYP      841  294  286   898  292  279   421  145  129\n",
       "SYN      782  272  265   842  259  266   402  129  122\n",
       "ANT      829  275  281   916  308  306   361  136  142\n",
       "RANDOM  2430  786  796  2554  877  887  1330  428  445"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stat_df = pd.DataFrame(stat_dict)\n",
    "reformed_dict = {}\n",
    "for outerKey, innerDict in stat_dict.items():\n",
    "    for innerKey, values in innerDict.items():\n",
    "        reformed_dict[(outerKey,\n",
    "                       innerKey)] = values\n",
    "#print(reformed_dict)\n",
    "stat_df = pd.DataFrame(reformed_dict)\n",
    "stat_df\n",
    "#stat_df.to_latex(\"./stats/data_stats.tex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-north",
   "metadata": {},
   "source": [
    "# Training Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "national-halifax",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare DataFrames\n",
    "comp_train_de = old_train_de.compare(new_train_de, keep_equal=True)\n",
    "comp_train_en = old_train_en.compare(new_train_en, keep_equal=True)\n",
    "comp_val_de = old_val_de.compare(new_val_de, keep_equal=True)\n",
    "comp_val_en = old_val_en.compare(new_val_en, keep_equal=True)\n",
    "comp_test_de = old_test_de.compare(new_test_de, keep_equal=True)\n",
    "comp_test_en = old_test_en.compare(new_test_en, keep_equal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4b280e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare DataFrames\n",
    "comp_train_de = old_train_de.applymap(lambda s:s.lower() if type(s) == str else s).\\\n",
    "compare(new_train_de.applymap(lambda s:s.lower() if type(s) == str else s), keep_equal=True)\n",
    "comp_train_en = old_train_en.applymap(lambda s:s.lower() if type(s) == str else s).\\\n",
    "compare(new_train_en.applymap(lambda s:s.lower() if type(s) == str else s), keep_equal=True)\n",
    "comp_val_de = old_val_de.applymap(lambda s:s.lower() if type(s) == str else s).\\\n",
    "compare(new_val_de.applymap(lambda s:s.lower() if type(s) == str else s), keep_equal=True)\n",
    "comp_val_en = old_val_en.applymap(lambda s:s.lower() if type(s) == str else s).\\\n",
    "compare(new_val_en.applymap(lambda s:s.lower() if type(s) == str else s), keep_equal=True)\n",
    "comp_test_de = old_test_de.applymap(lambda s:s.lower() if type(s) == str else s).\\\n",
    "compare(new_test_de.applymap(lambda s:s.lower() if type(s) == str else s), keep_equal=True)\n",
    "comp_test_en = old_test_en.applymap(lambda s:s.lower() if type(s) == str else s).\\\n",
    "compare(new_test_en.applymap(lambda s:s.lower() if type(s) == str else s), keep_equal=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a9293d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "hyp       385\n",
       "syn       255\n",
       "ant       202\n",
       "random    164\n",
       "Name: self, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_train_de[\"Relation\"][\"self\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "computational-option",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [(comp_train_de, comp_train_en, \"placeholder\"),\n",
    "        (comp_val_de, comp_val_en, \"placeholder\"), \n",
    "        (comp_test_de, comp_test_en, \"placeholder\")]\n",
    "usage = [\"Train\", \"Val\", \"Test\"]\n",
    "langs = [\"DE\", \"EN\", \"ZH\"]\n",
    "\n",
    "changed_stats = {}\n",
    "for idx, lang in enumerate(langs):\n",
    "    for d, us in zip(data,usage):\n",
    "        #print(us)\n",
    "        for rel in [\"hyp\", \"syn\", \"ant\", \"random\" ]:\n",
    "            ready = True\n",
    "            if lang == \"ZH\":\n",
    "                ready = False\n",
    "            else:\n",
    "                try:\n",
    "                    d[idx][\"Relation\"][\"self\"].value_counts()[rel]\n",
    "                    #print(lang, rel, rel, d[\"Relation\"][\"self\"].value_counts()[rel])\n",
    "                    ready = True                \n",
    "                except Exception as e:\n",
    "                    #print(lang, rel, rel, \"TBD\")\n",
    "                    print(lang, us, e)\n",
    "                    ready = False\n",
    "            if ready:\n",
    "                if (lang, us) not in changed_stats.keys():\n",
    "                    changed_stats[(lang, us)] = {rel: d[idx][\"Relation\"][\"self\"].value_counts()[rel]}\n",
    "                else:\n",
    "                    changed_stats[(lang, us)][rel] = d[idx][\"Relation\"][\"self\"].value_counts()[rel]\n",
    "            else:\n",
    "                if (lang, us) not in changed_stats.keys():\n",
    "                    changed_stats[(lang, us)] = {rel: \"TBD\"}\n",
    "                else:\n",
    "                    changed_stats[(lang, us)][rel] = \"TBD\"\n",
    "\n",
    "\n",
    "#print(changed_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "english-landing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">DE</th>\n",
       "      <th colspan=\"3\" halign=\"left\">EN</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ZH</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Train</th>\n",
       "      <th>Val</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train</th>\n",
       "      <th>Val</th>\n",
       "      <th>Test</th>\n",
       "      <th>Train</th>\n",
       "      <th>Val</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>hyp</th>\n",
       "      <td>385</td>\n",
       "      <td>150</td>\n",
       "      <td>92</td>\n",
       "      <td>319</td>\n",
       "      <td>149</td>\n",
       "      <td>121</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>syn</th>\n",
       "      <td>255</td>\n",
       "      <td>93</td>\n",
       "      <td>77</td>\n",
       "      <td>291</td>\n",
       "      <td>103</td>\n",
       "      <td>115</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ant</th>\n",
       "      <td>202</td>\n",
       "      <td>79</td>\n",
       "      <td>67</td>\n",
       "      <td>310</td>\n",
       "      <td>117</td>\n",
       "      <td>93</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>random</th>\n",
       "      <td>164</td>\n",
       "      <td>45</td>\n",
       "      <td>13</td>\n",
       "      <td>206</td>\n",
       "      <td>69</td>\n",
       "      <td>60</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "      <td>TBD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          DE              EN              ZH          \n",
       "       Train  Val Test Train  Val Test Train  Val Test\n",
       "hyp      385  150   92   319  149  121   TBD  TBD  TBD\n",
       "syn      255   93   77   291  103  115   TBD  TBD  TBD\n",
       "ant      202   79   67   310  117   93   TBD  TBD  TBD\n",
       "random   164   45   13   206   69   60   TBD  TBD  TBD"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "change_df = pd.DataFrame(changed_stats)\n",
    "change_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "civic-lender",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change_df.to_latex(\"./stats/change_stats.tex\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "polish-campaign",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HYP       320\n",
       "ANT       311\n",
       "SYN       293\n",
       "RANDOM    213\n",
       "Name: self, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_df = old_train_en.compare(new_train_en, keep_equal=True)\n",
    "comp_df[\"Relation\"][\"self\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "about-intro",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "      <th>Change in %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [self, other, Change in %]\n",
       "Index: []"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_counts = comp_df[\"Relation\"][\"self\"].value_counts(sort=False).compare(comp_df[\"Relation\"][\"other\"].value_counts(sort=False))\n",
    "comp_counts[\"Change in %\"] = round((comp_counts.other - comp_counts.self)/comp_counts.self * 100, 2)\n",
    "comp_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "gothic-ghana",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_HYP_idx = comp_df.index[comp_df[\"Relation\"][\"self\"].str.contains(\"HYP\", na=False)]\n",
    "old_SYN_idx = comp_df.index[comp_df[\"Relation\"][\"self\"].str.contains(\"SYN\", na=False)]\n",
    "old_ANT_idx = comp_df.index[comp_df[\"Relation\"][\"self\"].str.contains(\"ANT\", na=False)]\n",
    "old_RND_idx = comp_df.index[comp_df[\"Relation\"][\"self\"].str.contains(\"RANDOM\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "independent-oasis",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYP was changed to:\n",
      "\n",
      "SYN 19 times\n",
      "ANT 2 times\n",
      "RANDOM 1 times\n",
      "\n",
      "HYP was kept:\n",
      "\n",
      "298 times\n"
     ]
    }
   ],
   "source": [
    "#hyp_to = comp_df.loc[old_HYP_idx][\"Relation\"][\"other\"].drop(comp_df.loc[old_HYP_idx].index[comp_df.loc[old_HYP_idx].Relation.other == \"HYP\"]).value_counts()\n",
    "print(\"HYP was changed to:\\n\")\n",
    "for index, value in comp_df.loc[old_HYP_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index != \"HYP\":\n",
    "        print(index, value, \"times\")\n",
    "print(\"\\nHYP was kept:\\n\")\n",
    "for index, value in comp_df.loc[old_HYP_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index == \"HYP\":\n",
    "        print(value, \"times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daily-absorption",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYN was changed to:\n",
      "\n",
      "HYP 19 times\n",
      "ANT 3 times\n",
      "RANDOM 1 times\n",
      "\n",
      "SYN was kept:\n",
      "\n",
      "270 times\n"
     ]
    }
   ],
   "source": [
    "print(\"SYN was changed to:\\n\")\n",
    "for index, value in comp_df.loc[old_SYN_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index != \"SYN\":\n",
    "        print(index, value, \"times\")\n",
    "print(\"\\nSYN was kept:\\n\")\n",
    "for index, value in comp_df.loc[old_SYN_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index == \"SYN\":\n",
    "        print(value, \"times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "compatible-denmark",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANT was changed to:\n",
      "\n",
      "SYN 3 times\n",
      "HYP 2 times\n",
      "\n",
      "ANT was kept:\n",
      "\n",
      "306 times\n"
     ]
    }
   ],
   "source": [
    "print(\"ANT was changed to:\\n\")\n",
    "for index, value in comp_df.loc[old_ANT_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index != \"ANT\":\n",
    "        print(index, value, \"times\")\n",
    "print(\"\\nANT was kept:\\n\")\n",
    "for index, value in comp_df.loc[old_ANT_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index == \"ANT\":\n",
    "        print(value, \"times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "pointed-hunger",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM was changed to:\n",
      "\n",
      "HYP 1 times\n",
      "SYN 1 times\n",
      "\n",
      "RANDOM was kept:\n",
      "\n",
      "211 times\n"
     ]
    }
   ],
   "source": [
    "print(\"RANDOM was changed to:\\n\")\n",
    "for index, value in comp_df.loc[old_RND_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index != \"RANDOM\":\n",
    "        print(index, value, \"times\")\n",
    "print(\"\\nRANDOM was kept:\\n\")\n",
    "for index, value in comp_df.loc[old_RND_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index == \"RANDOM\":\n",
    "        print(value, \"times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atomic-concentration",
   "metadata": {},
   "source": [
    "# Validation Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "incorporate-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df = old_val_en.compare(new_val_en, keep_equal=True)\n",
    "#comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "false-cover",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "      <th>Change in %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [self, other, Change in %]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_counts = comp_df[\"Relation\"][\"self\"].value_counts(sort=False).compare(comp_df[\"Relation\"][\"other\"].value_counts(sort=False))\n",
    "comp_counts[\"Change in %\"] = round((comp_counts.other - comp_counts.self)/comp_counts.self * 100, 2)\n",
    "comp_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "listed-express",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_HYP_idx = comp_df.index[comp_df[\"Relation\"][\"self\"].str.contains(\"HYP\", na=False)]\n",
    "old_SYN_idx = comp_df.index[comp_df[\"Relation\"][\"self\"].str.contains(\"SYN\", na=False)]\n",
    "old_ANT_idx = comp_df.index[comp_df[\"Relation\"][\"self\"].str.contains(\"ANT\", na=False)]\n",
    "old_RND_idx = comp_df.index[comp_df[\"Relation\"][\"self\"].str.contains(\"RANDOM\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "southwest-enough",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYP was changed to:\n",
      "\n",
      "SYN 20 times\n",
      "RANDOM 1 times\n",
      "\n",
      "HYP was kept:\n",
      "\n",
      "128 times\n"
     ]
    }
   ],
   "source": [
    "#hyp_to = comp_df.loc[old_HYP_idx][\"Relation\"][\"other\"].drop(comp_df.loc[old_HYP_idx].index[comp_df.loc[old_HYP_idx].Relation.other == \"HYP\"]).value_counts()\n",
    "print(\"HYP was changed to:\\n\")\n",
    "for index, value in comp_df.loc[old_HYP_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index != \"HYP\":\n",
    "        print(index, value, \"times\")\n",
    "print(\"\\nHYP was kept:\\n\")\n",
    "for index, value in comp_df.loc[old_HYP_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index == \"HYP\":\n",
    "        print(value, \"times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "iraqi-method",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYN was changed to:\n",
      "\n",
      "HYP 20 times\n",
      "\n",
      "SYN was kept:\n",
      "\n",
      "83 times\n"
     ]
    }
   ],
   "source": [
    "print(\"SYN was changed to:\\n\")\n",
    "for index, value in comp_df.loc[old_SYN_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index != \"SYN\":\n",
    "        print(index, value, \"times\")\n",
    "print(\"\\nSYN was kept:\\n\")\n",
    "for index, value in comp_df.loc[old_SYN_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index == \"SYN\":\n",
    "        print(value, \"times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "armed-honey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANT was changed to:\n",
      "\n",
      "RANDOM 3 times\n",
      "\n",
      "ANT was kept:\n",
      "\n",
      "114 times\n"
     ]
    }
   ],
   "source": [
    "print(\"ANT was changed to:\\n\")\n",
    "for index, value in comp_df.loc[old_ANT_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index != \"ANT\":\n",
    "        print(index, value, \"times\")\n",
    "print(\"\\nANT was kept:\\n\")\n",
    "for index, value in comp_df.loc[old_ANT_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index == \"ANT\":\n",
    "        print(value, \"times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "naval-buffer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM was changed to:\n",
      "\n",
      "ANT 3 times\n",
      "HYP 1 times\n",
      "\n",
      "RANDOM was kept:\n",
      "\n",
      "66 times\n"
     ]
    }
   ],
   "source": [
    "print(\"RANDOM was changed to:\\n\")\n",
    "for index, value in comp_df.loc[old_RND_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index != \"RANDOM\":\n",
    "        print(index, value, \"times\")\n",
    "print(\"\\nRANDOM was kept:\\n\")\n",
    "for index, value in comp_df.loc[old_RND_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index == \"RANDOM\":\n",
    "        print(value, \"times\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecological-farmer",
   "metadata": {},
   "source": [
    "# Test Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "parental-nelson",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_df = old_test_de.compare(new_test_de, keep_equal=True)\n",
    "#comp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "checked-reason",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>self</th>\n",
       "      <th>other</th>\n",
       "      <th>Change in %</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [self, other, Change in %]\n",
       "Index: []"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_counts = comp_df[\"Relation\"][\"self\"].value_counts(sort=False).compare(comp_df[\"Relation\"][\"other\"].value_counts(sort=False))\n",
    "comp_counts[\"Change in %\"] = round((comp_counts.other - comp_counts.self)/comp_counts.self * 100, 2)\n",
    "comp_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-arthritis",
   "metadata": {},
   "source": [
    "# Clean Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "superb-ratio",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_HYP_idx = comp_df.index[comp_df[\"Relation\"][\"self\"].str.contains(\"HYP\", na=False)]\n",
    "old_SYN_idx = comp_df.index[comp_df[\"Relation\"][\"self\"].str.contains(\"SYN\", na=False)]\n",
    "old_ANT_idx = comp_df.index[comp_df[\"Relation\"][\"self\"].str.contains(\"ANT\", na=False)]\n",
    "old_RND_idx = comp_df.index[comp_df[\"Relation\"][\"self\"].str.contains(\"RANDOM\", na=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "developing-afternoon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HYP was changed to:\n",
      "\n",
      "SYN 10 times\n",
      "ANT 6 times\n",
      "\n",
      "HYP was kept:\n",
      "\n",
      "150 times\n"
     ]
    }
   ],
   "source": [
    "#hyp_to = comp_df.loc[old_HYP_idx][\"Relation\"][\"other\"].drop(comp_df.loc[old_HYP_idx].index[comp_df.loc[old_HYP_idx].Relation.other == \"HYP\"]).value_counts()\n",
    "print(\"HYP was changed to:\\n\")\n",
    "for index, value in comp_df.loc[old_HYP_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index != \"HYP\":\n",
    "        print(index, value, \"times\")\n",
    "print(\"\\nHYP was kept:\\n\")\n",
    "for index, value in comp_df.loc[old_HYP_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index == \"HYP\":\n",
    "        print(value, \"times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "short-china",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SYN was changed to:\n",
      "\n",
      "HYP 10 times\n",
      "ANT 1 times\n",
      "RANDOM 1 times\n",
      "\n",
      "SYN was kept:\n",
      "\n",
      "122 times\n"
     ]
    }
   ],
   "source": [
    "print(\"SYN was changed to:\\n\")\n",
    "for index, value in comp_df.loc[old_SYN_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index != \"SYN\":\n",
    "        print(index, value, \"times\")\n",
    "print(\"\\nSYN was kept:\\n\")\n",
    "for index, value in comp_df.loc[old_SYN_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index == \"SYN\":\n",
    "        print(value, \"times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "mounted-teddy",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ANT was changed to:\n",
      "\n",
      "HYP 5 times\n",
      "SYN 2 times\n",
      "RANDOM 1 times\n",
      "\n",
      "ANT was kept:\n",
      "\n",
      "126 times\n"
     ]
    }
   ],
   "source": [
    "print(\"ANT was changed to:\\n\")\n",
    "for index, value in comp_df.loc[old_ANT_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index != \"ANT\":\n",
    "        print(index, value, \"times\")\n",
    "print(\"\\nANT was kept:\\n\")\n",
    "for index, value in comp_df.loc[old_ANT_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index == \"ANT\":\n",
    "        print(value, \"times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "final-gravity",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM was changed to:\n",
      "\n",
      "ANT 1 times\n",
      "HYP 1 times\n",
      "\n",
      "RANDOM was kept:\n",
      "\n",
      "301 times\n"
     ]
    }
   ],
   "source": [
    "print(\"RANDOM was changed to:\\n\")\n",
    "for index, value in comp_df.loc[old_RND_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index != \"RANDOM\":\n",
    "        print(index, value, \"times\")\n",
    "print(\"\\nRANDOM was kept:\\n\")\n",
    "for index, value in comp_df.loc[old_RND_idx][\"Relation\"][\"other\"].value_counts().items():\n",
    "    if index == \"RANDOM\":\n",
    "        print(value, \"times\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "needed-agenda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "ds_val = new_val_en.loc[new_val_en.duplicated(subset=[\"e1\",\"e2\"])]\n",
    "print(\"Duplicates:\", ds_val[\"Relation\"].count())\n",
    "for i, r in ds_val.iterrows():\n",
    "    print (i + 1, r[\"e1\"], r[\"e2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "extraordinary-costume",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "ds_train = new_train_en.loc[new_train_en.duplicated(subset=[\"e1\",\"e2\"])]\n",
    "print(\"Duplicates:\", ds_train[\"Relation\"].count())\n",
    "for i, r in ds_train.iterrows():\n",
    "    print (i + 1, r[\"e1\"], r[\"e2\"], r[\"Relation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dressed-correspondence",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "ds_test = new_test_en.loc[new_test_en.duplicated(subset=[\"e1\",\"e2\"])]\n",
    "print(\"Duplicates:\", ds_test[\"Relation\"].count())\n",
    "for i, r in ds_test.iterrows():\n",
    "    print (i + 1, r[\"e1\"], r[\"e2\"], r[\"Relation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dated-berkeley",
   "metadata": {},
   "source": [
    "## Clean reverse duplicates (Rename Variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "casual-combination",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_train_en_rev = old_train_en.rename(columns={\"e1\":\"e2\", \"e2\":\"e1\"})\n",
    "new_train_en_rev = new_train_en.rename(columns={\"e1\":\"e2\", \"e2\":\"e1\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "brutal-giant",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "dub_train = pd.concat([new_train_en, new_train_en_rev])\n",
    "print(\"Duplicates:\", dub_train.loc[dub_train.duplicated(subset=[\"e1\",\"e2\"])][\"e1\"].count())\n",
    "for i, r in dub_train.loc[dub_train.duplicated(subset=[\"e1\",\"e2\"])].iterrows():\n",
    "    print(i+1, r['e1'], r['e2'],r['Relation'], \"/\", new_train_en.loc[i]['Relation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "surrounded-leadership",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "new_val_en_rev = new_val_en.rename(columns={\"e1\":\"e2\", \"e2\":\"e1\"})\n",
    "old_val_en_rev = old_val_en.rename(columns={\"e1\":\"e2\", \"e2\":\"e1\"})\n",
    "dub_val = pd.concat([new_val_en, new_val_en_rev])\n",
    "print(\"Duplicates:\", dub_val.loc[dub_val.duplicated(subset=[\"e1\",\"e2\"])][\"e1\"].count())\n",
    "for i, r in dub_val.loc[dub_val.duplicated(subset=[\"e1\",\"e2\"])].iterrows():\n",
    "    print(i+1, r['e1'], r['e2'],r['Relation'], \"/\", new_val_en.loc[i]['Relation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "defined-symphony",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "new_test_en_rev = new_test_en.rename(columns={\"e1\":\"e2\", \"e2\":\"e1\"})\n",
    "old_test_en_rev = old_test_en.rename(columns={\"e1\":\"e2\", \"e2\":\"e1\"})\n",
    "dub_val = pd.concat([new_test_en, new_test_en_rev])\n",
    "print(\"Duplicates:\", dub_val.loc[dub_val.duplicated(subset=[\"e1\",\"e2\"])][\"e1\"].count())\n",
    "for i, r in dub_val.loc[dub_val.duplicated(subset=[\"e1\",\"e2\"])].iterrows():\n",
    "    print(i+1, r['e1'], r['e2'],r['Relation'], \"/\", new_test_en.loc[i]['Relation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "specified-salad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 0\n"
     ]
    }
   ],
   "source": [
    "dub_all = pd.concat([new_test_en, new_train_en, new_train_en_rev,new_val_en], ignore_index=False)\n",
    "print(\"Duplicates:\", dub_all.loc[dub_all.duplicated(subset=[\"e1\",\"e2\"])][\"e1\"].count())\n",
    "for i,r in dub_all.loc[dub_all.duplicated(subset=[\"e1\",\"e2\"], keep=False)].iterrows():\n",
    "    print(i +1, r[\"e1\"], r[\"e2\"], r[\"Relation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sunrise-bones",
   "metadata": {},
   "source": [
    "# Check original for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "anticipated-stamp",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicates: 106\n"
     ]
    }
   ],
   "source": [
    "old_train_zh_rev = old_train_zh.rename(columns={\"e1\":\"e2\", \"e2\":\"e1\"})\n",
    "dub_all = pd.concat([old_train_zh, old_train_zh_rev, old_val_zh, old_test_zh], ignore_index=False)\n",
    "print(\"Duplicates:\", dub_all.loc[dub_all.duplicated(subset=[\"e1\",\"e2\"])][\"e1\"].count())\n",
    "#for i,r in dub_all.loc[dub_all.duplicated(subset=[\"e1\",\"e2\"])].iterrows():\n",
    "#    print(i +1, r[\"e1\"], r[\"e2\"], r[\"Relation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "hydraulic-failure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate change types without pandas\n",
    "import glob\n",
    "\n",
    "datasets = [\"train\", \"validgold\", \"gold\"]\n",
    "langs = [\"german\", \"english\"]\n",
    "changed_words_per_lang ={}\n",
    "change_per_lang = {}\n",
    "words_per_lang_orig = {}\n",
    "\n",
    "for lang in langs:\n",
    "    if lang not in change_per_lang.keys():\n",
    "        change_per_lang[lang] = {}\n",
    "        changed_words_per_lang[lang] = []\n",
    "        words_per_lang_orig[lang] = []\n",
    "    for dataset in datasets:\n",
    "        if dataset not in change_per_lang[lang].keys():\n",
    "            change_per_lang[lang][dataset] = {}\n",
    "        orig = open(f\"../CogALex 1.0/{dataset}_{lang}_data.txt\", \"r\", encoding=\"utf-8\").readlines()\n",
    "        new = open(f\"../CogALex 2.0/{dataset}_{lang}_data_new.txt\", \"r\", encoding=\"utf-8\").readlines()\n",
    "        # Capitalization check\n",
    "        change_per_lang[lang][dataset][\"cap\"] = 0\n",
    "        change_per_lang[lang][dataset][\"word\"] = 0\n",
    "        change_per_lang[lang][dataset][\"underscore\"] = 0\n",
    "        change_per_lang[lang][dataset][\"rel\"] = 0\n",
    "        for line_orig, line_new in zip(orig, new):\n",
    "            words_orig = line_orig.split(\"\\t\")\n",
    "            words_new = line_new.split(\"\\t\")\n",
    "            for idx, (o, n) in enumerate(zip(words_orig, words_new)):\n",
    "                o = o.strip()\n",
    "                n = n.strip()\n",
    "                \n",
    "                if idx < 2:\n",
    "                    words_per_lang_orig[lang].append(o)\n",
    "                    if o[:3] != n[:3] and o[:3].lower() == n[:3].lower():\n",
    "                        change_per_lang[lang][dataset][\"cap\"] += 1\n",
    "                    elif \"_\" in o:\n",
    "                        if o.split(\"_\")[0] in n:\n",
    "                            change_per_lang[lang][dataset][\"underscore\"] += 1\n",
    "                        else:\n",
    "                            pass\n",
    "                    elif o.lower() != n.lower():\n",
    "                        change_per_lang[lang][dataset][\"word\"] += 1\n",
    "                        changed_words_per_lang[lang].append(o)                \n",
    "                if idx >= 2:\n",
    "                    if o != n:\n",
    "                        change_per_lang[lang][dataset][\"rel\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "occupational-restoration",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'german': {'train': {'cap': 3214, 'word': 912, 'underscore': 0, 'rel': 485}, 'validgold': {'cap': 1021, 'word': 365, 'underscore': 0, 'rel': 124}, 'gold': {'cap': 1004, 'word': 299, 'underscore': 0, 'rel': 38}}, 'english': {'train': {'cap': 16, 'word': 914, 'underscore': 254, 'rel': 52}, 'validgold': {'cap': 3, 'word': 442, 'underscore': 69, 'rel': 48}, 'gold': {'cap': 3, 'word': 405, 'underscore': 71, 'rel': 28}}}\n"
     ]
    }
   ],
   "source": [
    "print(change_per_lang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "22d31228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'german': {'bumsen': 14, 'alb': 9, 'richtiggehend': 9, 'ausnehmen': 8, 'wild': 8, 'grenzen': 7, 'bereichern': 7, 'repräsentativ': 7, 'los': 7, 'auflösung': 7, 'persönlichkeit': 7, 'räumlich': 7, 'vorstehen': 7, 'hinweisen': 7, 'agentur': 7, 'verbauen': 6, 'beziehen': 6, 'gatter': 6, 'vermindern': 6, 'kunstvoll': 6, 'üppig': 6, 'wandzeitung': 6, 'dunkel': 6, 'stramm': 6, 'radikal': 5, 'vorstellbar': 5, 'energisch': 5, 'unfrei': 5, 'verfügen': 5, 'torpedieren': 5, 'umreißen': 5, 'nähern': 5, 'propagandist': 5, 'lernen': 5, 'kriminalität': 5, 'verwirren': 5, 'zeit': 5, 'tätigen': 5, 'unschuldig': 5}, 'english': {'geologic': 10, 'pulmonary': 10, 'commitment': 9, 'symbolism': 9, 'linguistic': 8, 'dimensional': 8, 'sexuality': 8, 'psychology': 8, 'philosophical': 7, 'rationale': 7, 'pontificate': 7, 'unnoticed': 7, 'citation': 7, 'zone': 7, 'promotional': 7, 'uterine': 7, 'cyclonic': 7, 'slider': 7, 'arbor': 6, 'symbolic': 6, 'nihilistic': 6, 'nationality': 6, 'unknown': 6, 'digestive': 6, 'kiwi': 6, 'disadvantageous': 6, 'representative': 6, 'matter': 6, 'postal': 6, 'pneumatic': 6, 'rub': 6, 'oceanic': 6, 'zebra': 5, 'skunk': 5, 'chemical': 5, 'endemic': 5, 'tomato': 5, 'neural': 5, 'iconic': 5, 'groove': 5, 'halter': 5, 'tribal': 5, 'provident': 5, 'blueberry': 5, 'evidence': 5, 'measurement': 5}}\n"
     ]
    }
   ],
   "source": [
    "word_change_count = {}\n",
    "for lang in langs:\n",
    "    word_change_count[lang] = {}\n",
    "    for i in set(changed_words_per_lang[lang]):\n",
    "        word_change_count[lang][i] = changed_words_per_lang[lang].count(i)\n",
    "    word_change_count[lang] = {k: v for k, v in sorted(word_change_count[lang].items(), key=lambda x: x[1], reverse=True)\n",
    "                              if v >= 5}\n",
    "print(word_change_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5e5b4301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[63, 59, 49]\n",
      "[71, 67, 55]\n",
      "{'german': {'abschneiden': 63, 'komplex': 59, 'verbauen': 49}, 'english': {'fight': 71, 'corrupt': 67, 'knowledgeable': 55}}\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "most_common_words = {}\n",
    "\n",
    "for lang in langs:\n",
    "    most_common_words[lang] = {}\n",
    "    for i in set(words_per_lang_orig[lang]):\n",
    "        most_common_words[lang][i] = words_per_lang_orig[lang].count(i)\n",
    "    print(heapq.nlargest(3, most_common_words[lang].values()))\n",
    "    most_common_words[lang] = {k: v for k, v in sorted(most_common_words[lang].items(), key=lambda x: x[1], reverse=True)\n",
    "                              if v in heapq.nlargest(3,most_common_words[lang].values())}\n",
    "print(most_common_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "03818c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check duplicates without pandas\n",
    "datasets = [\"train\", \"validgold\", \"gold\"]\n",
    "langs = [\"german\", \"english\", \"chinese\"]\n",
    "duplicates = {}\n",
    "\n",
    "for lang in langs:\n",
    "    if lang not in duplicates.keys():\n",
    "        duplicates[lang] = {\"count_all\": 0, \"count_norm\": 0, \"count_rev\": 0, \n",
    "                            \"pairs_norm\": [], \"pairs_rev\": []}\n",
    "    train = open(f\"../CogALex 1.0/train_{lang}_data.txt\", \"r\", encoding=\"utf-8\").readlines()\n",
    "    val = open(f\"../CogALex 1.0/validgold_{lang}_data.txt\", \"r\", encoding=\"utf-8\").readlines()\n",
    "    test = open(f\"../CogALex 1.0/gold_{lang}_data.txt\",\"r\", encoding=\"utf-8\").readlines()\n",
    "    words_train = [(w.split(\"\\t\")[0], w.split(\"\\t\")[1]) for w in train]\n",
    "    words_val = [(w.split(\"\\t\")[0], w.split(\"\\t\")[1]) for w in val]\n",
    "    words_test = [(w.split(\"\\t\")[0], w.split(\"\\t\")[1]) for w in test]\n",
    "    for other in [words_val, words_test]:\n",
    "        for pair in words_train:\n",
    "            if pair in other:\n",
    "                duplicates[lang][\"count_all\"] += 1\n",
    "                duplicates[lang][\"count_norm\"] += 1\n",
    "                duplicates[lang][\"pairs_norm\"].append(pair)\n",
    "                \n",
    "            elif (pair[1], pair[0]) in other: \n",
    "                duplicates[lang][\"count_all\"] += 1\n",
    "                duplicates[lang][\"count_rev\"] += 1\n",
    "                duplicates[lang][\"pairs_rev\"].append((pair[1], pair[0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7cd85dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'german': {'count_all': 26, 'count_norm': 22, 'count_rev': 4, 'pairs_norm': [('überziehen', 'anhäufen'), ('harmonisch', 'unharmonisch'), ('auflösung', 'verbindung'), ('recherche', 'wissensaneignung'), ('grün', 'türkis'), ('unübersehbar', 'eindeutig'), ('bestehen', 'andauern'), ('operativ', 'standardisiert'), ('wandzeitung', 'fußboden'), ('verhandlung', 'debatte'), ('schmieren', 'auftragen'), ('bestehen', 'standhalten'), ('rassistisch', 'menschenfeindlich'), ('erfrischend', 'ermüdend'), ('schmeicheln', 'hofieren'), ('naheliegend', 'erklärend'), ('richtiggehend', 'geradezu'), ('wild', 'hemmungslos'), ('ausnehmen', 'hineinstecken'), ('bock', 'schaf'), ('materialsammlung', 'archiv'), ('durchbrechen', 'verwundern')], 'pairs_rev': [('ästhetisch', 'kunstvoll'), ('erfordern', 'bedürfen'), ('heiter', 'düster'), ('düster', 'dunkel')]}, 'english': {'count_all': 34, 'count_norm': 27, 'count_rev': 7, 'pairs_norm': [('mortal', 'life_threatening'), ('unsatisfactory', 'acceptable'), ('misconstrue', 'beautify'), ('mantle', 'hole'), ('representative', 'symbolic'), ('proportionate', 'balanced'), ('allude', 'reference'), ('stone', 'fluid'), ('foot', 'body_parts'), ('progressive', 'innovative'), ('unrefined', 'refined'), ('indispensable', 'important'), ('dimensional', 'proportional'), ('swat', 'flat'), ('matter', 'empty'), ('misconstrue', 'twist'), ('deteriorate', 'build'), ('oceanic', 'watery'), ('omnivore', 'polyphage'), ('parody', 'mimicry'), ('fight', 'hit'), ('vague', 'ambiguous'), ('vague', 'uncertain'), ('alleviation', 'ease'), ('educator', 'relator'), ('nihilistic', 'new'), ('park', 'cuddle')], 'pairs_rev': [('symbolic', 'iconic'), ('misconstrue', 'construe'), ('groove', 'recreation'), ('polish', 'rub'), ('education', 'training'), ('unfavorable', 'disadvantageous'), ('pulmonary', 'pneumatic')]}, 'chinese': {'count_all': 50, 'count_norm': 0, 'count_rev': 50, 'pairs_norm': [], 'pairs_rev': [('順道', '特意'), ('父', '母親'), ('特地', '順道'), ('強烈', '弱'), ('之下', '之上'), ('良性', '惡性'), ('之后', '之前'), ('利益', '弊'), ('只不過', '祇'), ('以內', '外面'), ('裡頭', '外面'), ('媽媽', '父'), ('四川省', '四川'), ('更何況', '何況'), ('右', '左邊'), ('外面', '內部'), ('一點兒', '一點'), ('不僅僅', '不只'), ('吞下去', '吞'), ('這樣', '這樣子'), ('只不過', '祇是'), ('先生', '太太'), ('不僅僅', '不止'), ('不然', '要不然'), ('弊', '好處'), ('不到', '到'), ('開', '關'), ('哥哥', '弟'), ('行', '不行'), ('指引', '失落'), ('出於', '來自於'), ('以前', '後'), ('入', '出來'), ('研究院', '研究所'), ('之內', '之外'), ('吃掉', '吃下去'), ('以下', '之上'), ('圍起來', '圍起'), ('直接', '間接'), ('弟兄', '姐妹'), ('夫', '妻子'), ('只是', '祇不過'), ('有心人士', '有心人'), ('臺南', '台南'), ('下臺', '上台'), ('洗衣', '洗衣服'), ('下面', '之上'), ('最少', '最多'), ('要不然', '要不'), ('白', '黑')]}}\n"
     ]
    }
   ],
   "source": [
    "print(duplicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f0d7020",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
